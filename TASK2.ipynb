{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "r7asf3G721Dm",
        "outputId": "55f051c8-9519-4e1a-fa5d-781e0ac54a8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "XI5brb7I21-F"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/My Drive/forecasting-unit-sales-vit-task-2/train.csv'\n",
        "test_path = '/content/drive/My Drive/forecasting-unit-sales-vit-task-2/test.csv'\n",
        "sample_path = '/content/drive/My Drive/forecasting-unit-sales-vit-task-2/sample_submission.csv'"
      ],
      "metadata": {
        "id": "AjRXv6X43Tew"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(train_path)\n",
        "test_data = pd.read_csv(test_path)\n",
        "sample_data = pd.read_csv(sample_path)"
      ],
      "metadata": {
        "id": "P_DGuhwq3WHW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head(), test_data.head(), sample_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hXmF8TZtrHEc",
        "outputId": "e81e7899-c396-49b2-8c67-122c1cbb98a0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                      ID        date     Item Id  \\\n",
              " 0  2022-04-12_B09KDTS4DC  2022-04-12  B09KDTS4DC   \n",
              " 1  2022-04-12_B09MR2MLZH  2022-04-12  B09MR2MLZH   \n",
              " 2  2022-04-12_B09KSYL73R  2022-04-12  B09KSYL73R   \n",
              " 3  2022-04-12_B09KT5HMNY  2022-04-12  B09KT5HMNY   \n",
              " 4  2022-04-12_B09KTF8ZDQ  2022-04-12  B09KTF8ZDQ   \n",
              " \n",
              "                                            Item Name  ad_spend anarix_id  \\\n",
              " 0  NapQueen Elizabeth 8\" Gel Memory Foam Mattress...       NaN  NAPQUEEN   \n",
              " 1  NapQueen 12 Inch Bamboo Charcoal Queen Size Me...       NaN  NAPQUEEN   \n",
              " 2     NapQueen Elsa 8\" Innerspring Mattress, Twin XL       NaN  NAPQUEEN   \n",
              " 3        NapQueen Elsa 6\" Innerspring Mattress, Twin       NaN  NAPQUEEN   \n",
              " 4     NapQueen Elsa 6\" Innerspring Mattress, Twin XL       NaN  NAPQUEEN   \n",
              " \n",
              "    units  unit_price  \n",
              " 0    0.0         0.0  \n",
              " 1    0.0         0.0  \n",
              " 2    0.0         0.0  \n",
              " 3    0.0         0.0  \n",
              " 4    0.0         0.0  ,\n",
              "                       ID        date     Item Id  \\\n",
              " 0  2024-07-01_B09KDR64LT  2024-07-01  B09KDR64LT   \n",
              " 1  2024-07-01_B09KDTS4DC  2024-07-01  B09KDTS4DC   \n",
              " 2  2024-07-01_B09KDTHJ6V  2024-07-01  B09KDTHJ6V   \n",
              " 3  2024-07-01_B09KDQ2BWY  2024-07-01  B09KDQ2BWY   \n",
              " 4  2024-07-01_B09KDYY3SB  2024-07-01  B09KDYY3SB   \n",
              " \n",
              "                                            Item Name  ad_spend anarix_id  \\\n",
              " 0  NapQueen Elizabeth 10\" Gel Memory Foam Mattres...       NaN  NAPQUEEN   \n",
              " 1  NapQueen Elizabeth 8\" Gel Memory Foam Mattress...       NaN  NAPQUEEN   \n",
              " 2  NapQueen Elizabeth 12\" Gel Memory Foam Mattres...       NaN  NAPQUEEN   \n",
              " 3  NapQueen Elizabeth 12\" Gel Memory Foam Mattres...       NaN  NAPQUEEN   \n",
              " 4  NapQueen Elizabeth 10\" Gel Memory Foam Mattres...    101.72  NAPQUEEN   \n",
              " \n",
              "    unit_price  \n",
              " 0         0.0  \n",
              " 1         0.0  \n",
              " 2         0.0  \n",
              " 3         0.0  \n",
              " 4      1094.5  ,\n",
              "                       ID  units    TARGET\n",
              " 0  2024-07-01_B09KDTS4DC    NaN -2.923211\n",
              " 1  2024-07-02_B09KDTS4DC    NaN -1.992157\n",
              " 2  2024-07-03_B09KDTS4DC    NaN -6.185509\n",
              " 3  2024-07-04_B09KDTS4DC    NaN -5.878580\n",
              " 4  2024-07-05_B09KDTS4DC    NaN -5.962086)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to train SARIMA model on aggregated data and make predictions\n",
        "def train_sarima_and_predict_aggregated(train_data, test_data):\n",
        "    # Aggregate the training data by date\n",
        "    aggregated_train_data = train_data.groupby('date').agg({'units': 'sum'}).reset_index()\n",
        "\n",
        "    # Set date as index\n",
        "    aggregated_train_data.set_index('date', inplace=True)\n",
        "\n",
        "    # Train SARIMA model on aggregated data\n",
        "    sarima_model = SARIMAX(aggregated_train_data['units'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
        "    sarima_results = sarima_model.fit(disp=False)\n",
        "\n",
        "    # Forecast for each unique date in test set\n",
        "    test_dates = test_data['date'].unique()\n",
        "    forecast = sarima_results.get_forecast(steps=len(test_dates))\n",
        "    predicted_units = forecast.predicted_mean\n",
        "\n",
        "    # Map predictions back to test_data\n",
        "    date_predictions = pd.DataFrame({'date': test_dates, 'predicted_units': predicted_units})\n",
        "\n",
        "    return date_predictions\n",
        "\n",
        "# Load the datasets\n",
        "train_data = pd.read_csv('/content/drive/My Drive/forecasting-unit-sales-vit-task-2/train.csv')\n",
        "test_data = pd.read_csv('/content/drive/My Drive/forecasting-unit-sales-vit-task-2/test.csv')\n",
        "submission_data = pd.read_csv('/content/drive/My Drive/forecasting-unit-sales-vit-task-2/sample_submission.csv')\n",
        "\n",
        "# Convert date columns to datetime format\n",
        "train_data['date'] = pd.to_datetime(train_data['date'])\n",
        "test_data['date'] = pd.to_datetime(test_data['date'])\n",
        "\n",
        "# Ensure the data is sorted by date\n",
        "train_data = train_data.sort_values('date')\n",
        "test_data = test_data.sort_values('date')\n",
        "\n",
        "# Select relevant columns\n",
        "train_data = train_data[['date', 'Item Id', 'units', 'unit_price']]\n",
        "test_data = test_data[['date', 'Item Id', 'unit_price']]\n",
        "\n",
        "# Handle missing values\n",
        "train_data.dropna(subset=['Item Id', 'units'], inplace=True)\n",
        "\n",
        "# Get predictions for aggregated data\n",
        "aggregated_predictions = train_sarima_and_predict_aggregated(train_data, test_data)\n",
        "\n",
        "# Merge predictions with test_data on date using suffixes\n",
        "test_data = test_data.merge(aggregated_predictions, on='date', how='left', suffixes=('_test', '_pred'))\n",
        "\n",
        "# Ensure the column name 'predicted_units' is correct\n",
        "if 'predicted_units_pred' in test_data.columns:\n",
        "    test_data.rename(columns={'predicted_units_pred': 'predicted_units'}, inplace=True)\n",
        "\n",
        "# Create the ID column\n",
        "test_data['ID'] = test_data['date'].dt.strftime('%Y-%m-%d') + '_' + test_data['Item Id']\n",
        "\n",
        "# Filter the necessary columns and remove NaN values\n",
        "sample_data = test_data[['ID', 'predicted_units']].rename(columns={'predicted_units': 'TARGET'}).dropna()\n",
        "\n",
        "# Save the submission file\n",
        "sample_data.to_csv('/content/drive/My Drive/forecasting-unit-sales-vit-task-2/sampleSubmission.csv', index=False)\n",
        "\n",
        "print(sample_data.head())\n"
      ],
      "metadata": {
        "id": "JBZh26xj53iC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8097aeb6-a457-41e4-c3fb-d0886830cc88"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      ID      TARGET\n",
            "0  2024-07-01_B09KDR64LT  1006.09442\n",
            "1  2024-07-01_B0BNL11QD8  1006.09442\n",
            "2  2024-07-01_B0BDRS6R5Z  1006.09442\n",
            "3  2024-07-01_B0BNL4L4K5  1006.09442\n",
            "4  2024-07-01_B0BNL3J36Z  1006.09442\n"
          ]
        }
      ]
    }
  ]
}